{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "PATH_DRIVERS = \"driver_imgs_list.csv\"\n",
    "CATEGORIES = [\"c0\",\"c1\",\"c2\",\"c3\",\"c4\",\"c5\",\"c6\",\"c7\",\"c8\",\"c9\"]\n",
    "DATA_DIR = \"imgs/train\"\n",
    "LOAD_FROM_CACHE = True\n",
    "np.random.seed(2020)\n",
    "random_state = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, img_rows, img_cols, color_type=3):\n",
    "    \n",
    "    if color_type == 1:\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    resized_image = cv2.resize(image, (img_cols, img_rows))\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "def get_driver_dict():\n",
    "    \n",
    "    image_driver = dict()\n",
    "    driver_dict = dict()\n",
    "    file = open(PATH_DRIVERS, 'r')\n",
    "    line = file.readline()\n",
    "    \n",
    "    while(True):\n",
    "        line = file.readline()\n",
    "        if line == '':\n",
    "            break   \n",
    "        array = line.strip().split(',')\n",
    "        image_driver[array[2]] = array[0]\n",
    "        if array[0] not in driver_dict.keys():\n",
    "            driver_dict[array[0]] = [(array[1], array[2])]\n",
    "        else:\n",
    "            driver_dict[array[0]].append((array[1], array[2]))\n",
    "    \n",
    "    file.close()\n",
    "    return image_driver, driver_dict\n",
    "\n",
    "def load_images(img_rows, img_cols, color_type=1):\n",
    "    \n",
    "    images = []\n",
    "    images_id = []\n",
    "    labels = []  \n",
    "    driver_id = []\n",
    "    \n",
    "    image_driver, driver_dict = get_driver_dict()\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATA_DIR, category)\n",
    "        label = CATEGORIES.index(category)\n",
    "        \n",
    "        print(\"Load images from directory: \" + str(category))\n",
    "        for img in os.listdir(path):\n",
    "            \n",
    "            try:\n",
    "                image = read_image(os.path.join(path, img), img_rows, img_cols, color_type)     \n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                images_id.append(img)\n",
    "                driver_id.append(image_driver[img])\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "    unique_drivers = sorted(list(set(driver_id)))\n",
    "    print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "    print(unique_drivers)\n",
    "    \n",
    "    return images, labels, images_id, driver_id, unique_drivers\n",
    "\n",
    "def cache_data(data, path):\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.mkdir(os.path.dirname(path))\n",
    "        \n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "def select_drivers(images, labels, driver_id, selected_driver):\n",
    "    \n",
    "    selected_images = []\n",
    "    selected_labels = []\n",
    "    selected_index = []\n",
    "    \n",
    "    for index in range(len(driver_id)):\n",
    "        if driver_id[index] in selected_driver:\n",
    "            selected_images.append(images[index])\n",
    "            selected_labels.append(labels[index])\n",
    "            selected_index.append(index)\n",
    "    \n",
    "    return np.array(selected_images), np.array(selected_labels), np.array(selected_index)\n",
    "\n",
    "def read_images(img_rows, img_cols, color_type=3):\n",
    "    \n",
    "    cache_path = os.path.join('cache', 'images_' + str(img_rows) + 'x' + str(img_cols) + 'x' + str(color_type) + '.dat')\n",
    "    \n",
    "    if not os.path.isfile(cache_path) or LOAD_FROM_CACHE == False:\n",
    "        images, labels, images_id, driver_id, unique_drivers = load_images(img_rows, img_cols, color_type)\n",
    "        cache_data((images, labels, images_id, driver_id, unique_drivers), cache_path)\n",
    "    else:\n",
    "        print(\"Restore images from cache\")\n",
    "        (images, labels, images_id, driver_id, unique_drivers) = restore_data(cache_path)\n",
    "        \n",
    "    return images, labels, images_id, driver_id, unique_drivers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_folds(nfolds=5, img_rows=128, img_cols=128, color_type=3):\n",
    "    \n",
    "    images, labels, images_id, driver_id, unique_drivers = read_images(img_rows, img_cols, color_type)\n",
    "    num_fold = 0\n",
    "    kf = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for train_drivers, val_drivers in kf.split(unique_drivers):\n",
    "        \n",
    "        unique_train_drivers = [unique_drivers[i] for i in train_drivers]\n",
    "        X_train, Y_train, train_index = select_drivers(images, labels, driver_id, unique_train_drivers)\n",
    "        \n",
    "        unique_val_drivers = [unique_drivers[i] for i in val_drivers]\n",
    "        X_val, Y_val, val_index = select_drivers(images, labels, driver_id, unique_val_drivers)\n",
    "\n",
    "        num_fold += 1\n",
    "        \n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train))\n",
    "        print('Split valid: ', len(X_val))\n",
    "        print('Train drivers: ', unique_train_drivers)\n",
    "        print('Test drivers: ', unique_val_drivers)\n",
    "        \n",
    "        cache_path = os.path.join('cache/directory_128', 'k_' +  str(num_fold) + '.dat')\n",
    "        cache_data((X_train, Y_train, X_val, Y_val), cache_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of 5 folds (each driver is present once in th validation and four times in the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load images from directory: c0\n",
      "Load images from directory: c1\n",
      "Load images from directory: c2\n",
      "Load images from directory: c3\n",
      "Load images from directory: c4\n",
      "Load images from directory: c5\n",
      "Load images from directory: c6\n",
      "Load images from directory: c7\n",
      "Load images from directory: c8\n",
      "Load images from directory: c9\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "Start KFold number 1 from 5\n",
      "Split train:  17721\n",
      "Split valid:  4703\n",
      "Train drivers:  ['p002', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p047', 'p050', 'p051', 'p056', 'p061', 'p064', 'p066', 'p072', 'p081']\n",
      "Test drivers:  ['p012', 'p042', 'p045', 'p049', 'p052', 'p075']\n",
      "Start KFold number 2 from 5\n",
      "Split train:  17121\n",
      "Split valid:  5303\n",
      "Train drivers:  ['p002', 'p012', 'p014', 'p015', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p049', 'p050', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "Test drivers:  ['p016', 'p021', 'p022', 'p047', 'p051']\n",
      "Start KFold number 3 from 5\n",
      "Split train:  18492\n",
      "Split valid:  3932\n",
      "Train drivers:  ['p002', 'p012', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p039', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "Test drivers:  ['p014', 'p035', 'p041', 'p056', 'p061']\n",
      "Start KFold number 4 from 5\n",
      "Split train:  18114\n",
      "Split valid:  4310\n",
      "Train drivers:  ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p026', 'p035', 'p041', 'p042', 'p045', 'p047', 'p049', 'p051', 'p052', 'p056', 'p061', 'p066', 'p072', 'p075']\n",
      "Test drivers:  ['p024', 'p039', 'p050', 'p064', 'p081']\n",
      "Start KFold number 5 from 5\n",
      "Split train:  18248\n",
      "Split valid:  4176\n",
      "Train drivers:  ['p012', 'p014', 'p016', 'p021', 'p022', 'p024', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p075', 'p081']\n",
      "Test drivers:  ['p002', 'p015', 'p026', 'p066', 'p072']\n"
     ]
    }
   ],
   "source": [
    "create_k_folds(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
